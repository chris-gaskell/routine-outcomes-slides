---
from: markdown+emoji
format:
  revealjs:
    include-in-header: 
      text: |
        <meta name="github-repo" content="chris-gaskell/routine-outcomes-slides"/>
        <meta name="twitter:title" content="The effectiveness of psychological Interventions in routine practice"/>
        <meta name="twitter:description" content="Here are the slides from my presentation to the University of Sheffield"/>
        <meta name="twitter:url" content="https://routine-therapy-outcomes.netlify.app/"/>
        <meta name="twitter:image" content="https://github.com/chris-gaskell/routine-outcomes-slides/blob/master/front-cover.jpg?raw=true"/>
        <meta name="twitter:image:alt" content="The effectiveness of psychological Interventions in routine practice, 06/03/2023."/>
        <meta name="twitter:card" content="summary_large_image"/>
        <meta name="twitter:creator" content="@chrisgaskell92/>
        <meta name="twitter:site" content="@chrisgaskell92"/>
    smaller: false
    scrollable: true
    slide-tone: false
    incremental: false
    theme: [simple, custom.scss]
    preview-links: false
    preload-iframes: false
    chalkboard: true
    institute: "University of Sheffield"
    footer: "Effectiveness of Routine Psychological Interventions"
    transition: slide
    background-transition: fade
    transition-speed: slow
    footnotes-hover: true
    fig-cap-location: top
---

## The Effectiveness of Psychological Interventions in Routine Practice {style="font-size: 35px; text-align: center;"}

::: {style="text-align: center"}
*A research seminar for:*
:::

**The University of Sheffield Psychology**

::: {style="text-align: center"}
[routine-therapy-outcomes.netlify.app](https://routine-therapy-outcomes.netlify.app/){.uri style="text-align: center"}
:::

![](https://images.unsplash.com/photo-1507537362848-9c7e70b7b5c1?ixlib=rb-4.0.3&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=2340&q=80){fig-align="center" width="500" height="300"}

------------------------------------------------------------------------

::: columns
::: {.column width="50%" style="text-align: center"}
![](https://pbs.twimg.com/profile_images/1434417640920002563/ZS62zhXl_400x400.jpg){style="border-radius: 50%; box-shadow: 0 0 30px black;" width="240"}

### Dr. Chris Gaskell

::: {style="font-size: 24px; text-align: center"}
Senior Clinical Psychologist

Neuropsychology

North Staffordshire Combined Healthcare NHS Trust
:::

::: {.column width="50%" style="text-align: center"}
:::
:::
:::

------------------------------------------------------------------------

## Disclaimers {visibility="hidden"}

-   I'm learning too[^1] :student:

[^1]: Acknowledgements: to supervisors and co-authors: Dr Steve Kellett, Dr Mel Simmons-Buckley & Dr Jaime Delgadillo.

## Aims For This Talk {background-color="#01364C"}

::: columns
::: {.column width="50%"}
-   Overview of Practice Based Evidence.

-   Rationale for the Current Study.

-   Findings & Limitations.

-   Recent Developments.
:::
:::

::: {style="text-align: center; padding: 200px 0;"}
# Background {background-color="#01364C"}
:::

## What Have we Learnt from Psychotherapy Research RCTs?

-   Psychotherapy works! :white_check_mark:.

-   Different therapies fare about equal (i.e., **Dodo Bird Effect** :bird:).

-   Some therapists produce greater outcomes (**Super Shrinks?** :superhero:).

-   Providing feedback on progress leads to greater outcomes :up::mushroom:.

-   Much improvement is actually achieved in the early sessions.

::: notes
-   Lots of interesting findings that have come out of quantitative psychotherapy research.

-   I think that all of these findings are really interesting, particularly as someone who attempts to use therapy. I want to do a good job. So I take an interest in the area.

-   But there does come a point where, and it was probably early stages of clinical training, being on placements, that I couldn't help but question the veracity of some of the RCTs that get reported.

-   For me, working in my early clinical placements, Barnsley, how can the findings possible apply to the patient in front of me. How can this level of complexity be really represented in RCTs.
:::

## The Problems with RCTs?

::: columns
::: {.column width="50%"}
Advantages of RCTs

-   :white_check_mark: Reduction of bias

-   :white_check_mark: High internal validity

-   :white_check_mark: Reproducibility

-   :white_check_mark: Objective and reliable
:::

::: {.column width="50%"}
**However:**

-   :x: High cost and resource-intensive
-   :x: Ethical issues
-   :x: Limited external validity
:::
:::

::: notes
**Advantages**:

1.  **Reduction of bias:** RCTs use randomization to allocate participants into different groups, which helps reduce bias and ensure that the groups are comparable in terms of baseline characteristics.
2.  **High internal validity:** RCTs are considered the gold standard for evaluating the efficacy of interventions because they provide high internal validity, which means that they can establish causality between the intervention and the outcome.
3.  **Reproducibility:** RCTs provide a clear and detailed protocol for how the study was conducted, which allows other researchers to reproduce the study and test the results.
4.  **Objective and reliable:** RCTs use standardized methods to collect data, which ensures that the results are objective and reliable.

**Disadvantages:**

1.  **High cost and resource-intensive:** RCTs can be expensive and time-consuming, requiring significant funding and resources to conduct.
2.  **Ethical issues:** In some cases, RCTs may involve withholding treatment from participants in the control group, which can raise ethical concerns.
3.  **Limited external validity:** RCTs are often conducted in a highly controlled setting and may not fully reflect the real-world conditions in which the intervention will be used. RCTs may exclude certain groups of people, such as those with comorbidities or those who are pregnant, which can limit the generalizability of the results to those groups.
4.  **Limited scope:** RCTs are often designed to test a specific intervention, which means that they may not provide a comprehensive understanding of the broader context or underlying mechanisms.
:::

## But do Finding Hold True in (Routine) Practice?

Many reasons to expect that that the effects of psychotherapy delivered in routine care settings may **differ** from RCTS:

-   Geographical effects.

-   Provision.

-   Empirically Supported Treatments.

-   Integrity.

**So what do we do... ?**

::: notes
-   Important to continually monitor that treatments work under the conditions that they are purposefully designed for.

-   Lots of reasons why they may not apply.

    -   How does a service in Rotherham match the clinical in an RCT from an American University.

    -   How can we get the same results if we can provide the number of sessions, training etc. in trials.

    -   How can a service that aren't even using evidence based treatments claim to be as effective as ones that claim to do so.

    -   How can we be sure that we are really using the interventions that was used in the trials. In routine practice it's quite rare, particularly when qualified for anyone to assess if someone is actually using the intervention as intended.

-   How do we know this? We evaluate if things work in routine practice!
:::

## Practice-Based Evidence {background-color="white"}

::: columns
::: {.column width="50%"}
![](files/img/barkham-book.jpeg){style="box-shadow: 0 0 20px black;" width="398"}
:::

::: {.column width="50%"}
![](files/img/shaddish.jpg){style="box-shadow: 0 0 0px black;" width="600" height="600"}
:::
:::

::: notes
-   Well... the answer is. We shouldn't' assume that treatment effects automatically translate to routine practice.

-   We should monitor it. We should do complementary research in routine settings .

-   Different form of evidence - Practice based evidence (of effectiveness research).

    -   Sata generated from the actual practice.

    -   Typically gathered through systematic data collection from real-world settings.

        Practice-based evidence is particularly useful in fields where interventions are complex and multifaceted, and where there is a high degree of variability in the populations being served. Or rare conditions by which we wouldn't be able to recruit enough people or fund an RCT.

-   And this is really the bit that I became quite interested in. Doing research to check the things does actually work. Always felt relevant to me because, I work in routine practice, as I imaging may of you do too.

-   Book - Read it during first year: cited it in every assignment/publication I have done since.

-   Article - Synthesising the results across routine settings. So broadly speaking, when we look across research in routine practice, what do we see.
:::

## Hour Glass Model

![Salkovskis, P. M. (1995). Demonstrating specific effects in cognitive and behavioural therapy, in M. Aveline & D. Shapiro (Eds.), Research foundations for psychotherapy practice (pp. 191--228). Chichester, UK: Wiley. Taken from BABCP: https://babcp.com/Therapists/A-Cognitive-Behavioural-Therapists-Guide-to-Evidence](files/img/hour-glass.jpg)

::: notes
Paul Salkovskis has proposed an hour-glass model of psychological treatment, which is a variation of the hour-glass model of research. The model outlines the process of psychological treatment, from the initial assessment to the termination of treatment.

The hour-glass model of psychological treatment proposed by Paul Salkovskis typically involves the following stages:
:::

## Past Reviews of Practice Based Research

```{r}
#| include: true
#| eval: true
#| label: tbl-effectiveness-reviews
#| tbl-cap: "Findings from Past Effectiveness Reviews."
library(tidyverse)
library(gt)

gt::as_raw_html(
  
tribble(
  ~Paper, ~Condition, ~Treatment, ~Method, ~Studies,  ~Finding,
"Shaddish, Matt, Navarro & Phillips (2000)", "Various", "Various", "Meta-Analysis", "90", NA,
"Van Ingen, Freiheit & Vye (2009)", "Anxiety Disorders", "CBT", "Review & Meta-Analysis", "11", "d = 1.35 (d = 1.14 at follow up)",
"Stewart & Chambless (2009)", "Anxiety Disorders", "CBT", "Review & Meta-Analysis", "56","Panic (0.83 - 1.23)<br> SAD (0.73 - 1.04)<br>PTSD (1.62 - 2.59)<br>GAD (0.89 - 0.92)<br>OCD (0.89 - 1.32)<br>",
"Cahill, Barkham & Stiles (2010)", "Various", "Various", "Review & Meta-Analysis", "31", "d = 1.29",
"Hunsley, Elliott & Therrien (2014)", "Mood & Anxiety Disorders",  "Various", "Narrative Review", NA, NA,
"Wakefield, Kellett, Simmonds-Buckley, Stockton, Bradbury & Delgadillo (2020)", "Anxiety & Depression", "IAPT", "Meta-Analysis", "47", "Depression (d = 0.87)<br>Anxiety (d = 0.88)<br>Functioning (d = 0.55)"

) %>% 
  gt(#rowname_col = "Paper"
     ) %>% 
    tab_options(
    #row_group.background.color = "grey",
    row_group.font.size = 18,
    row_group.font.weight = "bold",
    column_labels.font.weight = "bold",
    table.font.size = 18,
    data_row.padding = px(6),
    table.width = pct(90),
    row_group.padding = px(5)
  ) %>%
  sub_missing(columns = 1:6, missing_text = "") %>%
  fmt_markdown(columns = everything()) %>%
  gt::opt_row_striping(row_striping = T) %>%
  opt_stylize(style = 6, color = "gray") %>%
  cols_width(
    Paper ~ px(200),
    Condition ~ px(100),
    Treatment ~ px(100),
    Method ~ px(100),
    Studies ~ px(60),
    Finding ~ px(150),
  ) %>% 
    tab_header(
    title = md("Past **Effectiveness** Reviews"),
  ) %>%
    cols_align(
    align = "center",
    columns = c(2:6)
    ) 
)

```

::: notes
-   So what does PBE have to say about if psychotherapy works?

-   Similar treatment outcomes are often found (e.g., Lutz et al., 2016; Persons et al., 1999).

-   When there is lots of different PBE studies. Varying a lot. Then what do we do... we do our best to synthesis the evidence.

-   Several attempts to synthesise the effects of therapy in routine settings.

-   Only including observational data. No control groups.

-   No experimental control, but good external validity.

-   Generally show that treatment is effective; with large effect-sizes reported across a range of conditions and treatments.

-   Apart from Wakefield paper. All done up until 2010. however limited to a single care sector.

    -   A lot of research has been conducted since then.

    -   Methods for synthesising research have developed.

    -   Change in trends, more places using EBP.
:::

## Rationale

-   Considerable growth of PBE in the last decade (and ESTs) :chart_with_upwards_trend:.

-   Previous reviews vary in focus/setting.

-   Benchmarks that apply to a broad range of services are warranted.

-   Limited prior attempt to explore why effect-sizes differ.

**Aim:** Broadly review the literature of PBE studies.

::: notes
-   Size and breadth.

-   Meta-analytic bencmarks, for services to compare to. All well and good knowing that across 50 studies the pooled effects-size is 1.0. But what does that mean for how my service is performing.

-   FINally, past reviews have been limited in attempting to explain WHY do some services within the meta-analysis have really large effects and some have really small effects.
:::

**Objectives:**

1.  Assess the degree to which treatments are effective.

2.  Provide benchmarks for services to compare to.

3.  Examine sources of heterogeneity using moderator variables.

    ::: notes
    Do this using.... Meta analysis
    :::

::: {style="text-align: center; padding: 200px 0;"}
# Method {background-color="#01364C"}
:::

## What is a Meta-Analysis? {background-color="white"}

-   Extract the effect-size from each study, and pool the results into a single effect.

-   Throwing everything into a bucket and seeing what comes out.

-   Problem: **Statistical Independence**

-   Various possible solutions

    -   Multiple meta-analyses!

![](files/img/buckets.jpg){fig-align="center"}

::: notes
-   Doing that thing psych love to do. Taking lots of numbers, as many as we can find,. And finding a way to reduce and explain that using one number.

-   Weighting.

-   Everything into one bucket.

-   However... we aren't interested in one thing. As many studies use multiple measures, we are going to want to potentially extract multiple effect-sizes from each study. Interested in if therapy is effective across conditions.

-   This is a problem because multiple ESs. that come from one study are going to be more similar (correlated) than two effect-sizes from different studies.

-   This is breaking the statistical assumption of independence. It has been a bit of a problem in these situations for a long time, various options:

-   Other, predominantly general distress, some of them diagnosis specific.

-   Multiple buckets (and there \[we will come back\] is one of the big limitations of this review).
:::

## Search Criteria

```{r}
#| include: true
#| eval: true
#| label: tbl-search-criteria
#| tbl-cap: "Search criteria used in the systematic review."
library(tidyverse)
library(gt)

gt::as_raw_html(
  
tribble(
  ~Effectiveness, ~Psychological, ~Limiters,
"Practice based evidence", "Psycho* OR Therap [PsycInfo]", "English Language",
"Routine practice", "Psycho* [CINAHL and MEDLINE]", "Adult Sample",
"Benchmarking", NA, NA,
"Transportability", NA, NA,
"Transferability", NA, NA,
"Clinical* representat", NA, NA,
"External valid* N0 findings", NA, NA,
"Applicab* N0 findings", NA, NA,
"Applicab* N0 intervention*", NA, NA,
"Empiric* support’ N0 treatment", NA, NA,
"Empiric* support’ N0 intervention", NA, NA,
"Clinical* Effective*’", NA, NA,
"Dissem* N0 treatment*", NA, NA,
"Dissem* N0 intervention*", NA, NA,
"Clinical Practice N0 intervention*", NA, NA,
"Clinical Practice N0 treatment*", NA, NA,
"Service deliv N0 intervention", NA, NA,
"Service deliv N0 treatment", NA, NA,
"Clinical* effective N2 evaluat", NA, NA,
"Service deliv N0 evaluat", NA, NA,
"Transporting", NA, NA,
"Managed care setting", NA, NA,
"Uncontrolled", NA, NA,
"Community clinic", NA, NA,
"Community mental health centre", NA, NA,
"Clinic setting", NA, NA,
"Service setting", NA, NA
) %>% 
  gt() %>% 
    tab_options(
    #row_group.background.color = "grey",
    row_group.font.size = 18,
    row_group.font.weight = "bold",
    column_labels.font.weight = "bold",
    table.font.size = 18,
    data_row.padding = px(6),
    table.width = pct(90),
    row_group.padding = px(5)
  ) %>%
  sub_missing(columns = 1:3, missing_text = "") %>%
  gt::opt_row_striping(row_striping = T) %>%
  opt_stylize(style = 6, color = "gray")

)

```

::: notes
These are the search terms used in the systematic search, largely informed by the terms used in previous reviews.
:::

## Moderators

```{r}
#| include: true
#| eval: true
#| label: tbl-moderator-definitions
#| tbl-cap: "Moderators used in the systematic review."

gt::as_raw_html(
  
tribble(
  ~Moderator,                         ~Type,              ~Levels,        ~Notes,
    "Setting",                       "Categorical", "a) Outpatient<br>b) Inpatient<br>c) Mixed", NA,
    "Analysis",                      "Categorical", "a) Included all patients<br>b) Only completers", NA,
    "Severity",                      "Categorical", "a) **Mild** services (primary care, physical health, university counselling, voluntary, private, EAP).<br>b) **Moderate** services (secondary care, CMHTs, specialist psychotherapy centers, managed care settings, or intensive outpatient programmes).<br>c) **Severe** services (inpatient samples).<br>d) **University** clinics (outpatient and training clinics).", NA,
    "Modality",                      "Categorical", "a) **Cognitive-behavioral**.<br>b) **Psychodynamic**.<br>c) **Counselling** (e.g., person-centred, undefined).<br>d) **Other**.", "based on manuscript self-designation (i.e., if the manuscript described treatment as CBT, then that was coded). In the absence of these terms, modality of best-fit was decided using treatment descriptions. ",
    "Continent",                      "Categorical", "a) North America.<br>b) United Kingdom (UK).<br>c) Mainland Europe.<br>d) Australasia.<br>e) Asia", "The UK was separated from Europe because of the high representation of outcomes research coming from the UK",
    "Intervention Development Stage", "Categorical", "a) Preliminary studies (i.e., novel treatments/conditions).<br>b) Routine evaluations.", NA,
    "Experience",                     "Categorical", "a) Trainees.<br>b) Qualified professionals.", NA,
    "Measurement Tool",               "Categorical", NA, "Measures that were represented at least ten times in the systematic review",
    "Sample Size",                   "Categorical", "a) Small (N ≤ 25).<br>b) Medium (N = 25–50).<br>c) large (N = 50+)", NA,
    "Age",                            "Continuous", "Mean average age of sample", NA,
    "Year",                           "Continuous", "Year of publication", NA,
    "Females",                        "Continuous", "Rate of females (%)", NA,
) %>%
  group_by(Type) %>% 
   gt() %>% 
  fmt_markdown(columns = everything()) %>%
  tab_options(
    row_group.background.color = "grey",
    row_group.font.size = 18,
    row_group.font.weight = "bold",
    column_labels.font.weight = "bold",
    table.font.size = 18,
    data_row.padding = px(6),
    table.width = pct(90),
    row_group.padding = px(5)
  ) %>%
  sub_missing(columns = 1:4, missing_text = "") %>%
  gt::opt_row_striping(row_striping = T) %>%
  opt_stylize(style = 6, color = "gray") %>%
  cols_width(
    Moderator ~ px(50),
    Type ~ px(50),
    Levels ~ px(150),
    Notes ~ px(150),
  )

)

```

::: notes
-   So with the buckets, we are reducing lots of studies down to a single number (effect-size).

-   Meta-analyses also tell us how much individual studies differ (heterogeneity).This is really interesting because it opens a question, why do some studies in the MA do really well and some do not. What variables explain.

-   Good news! MA can do this. It's debatable how good it is at doing this but nevertheless.

-   It allows us to select a number of variables, that studies may differ on, and establish there are systematic differences.

-   The idea is that these variables, or moderators, allow us to explain some of the variation.
:::

::: {style="text-align: center; padding: 200px 0;"}
# Findings {background-color="#01364C"}
:::

## PRISMA {background-color="white"}

![Prisma flow diagram of studies throughout the review](files/img/prisma.jpg){#fig-surus alt="Prisma flow diagram of studies throughout the review" fig-align="center"}

::: notes
-   This is a PRISMA. It is a graphical representation of the flow of information through a systematic review process.

-   90000 unique results.

-   Screened 600 papers.

-   223 in meta-analysis.
:::

## Rates of Effectiveness

```{r}
#| include: true
#| eval: true
#| label: tbl-summary-es
#| tbl-cap: "Sub-group (categorical) moderator analyses for depression outcomes."

gt::as_raw_html(
  
tribble(
  ~Outcome, ~k,	  ~d,	   ~ci,	            	~p,	     ~I2,	     ~Q,
"Depression",	140,	0.96,	"0.90-1.06",	 "< 0.001",	98.40,	3037.46,
"Anxiety",  	84,	  0.80,	"0.73-0.92",	 "< 0.001",	97.52,	1488.88,
"Other",  	184,	1.01,	"0.93-1.08",	 "< 0.001",	98.92,	15685.18
) %>% 
  gt()  %>%
  tab_options(
    row_group.font.size = 18,
    row_group.font.weight = "bold",
    column_labels.font.weight = "bold",
    table.font.size = 18,
    data_row.padding = px(10),
    table.width = pct(90),
    row_group.padding = px(5)
  )  %>%
    cols_label(
    k = md("*k*"),
    d = md("*d*"),
    ci = "95% CI",
    I2 = md("*I*<sup>2</sup>"),
    p = md("*p*")
    ) %>%
  sub_missing(columns = 1:7, missing_text = "-") %>%
  gt::opt_row_striping(row_striping = T) %>%
  opt_stylize(style = 6, color = "gray") %>%
   fmt_markdown(columns = everything()) %>%
cols_align(
  align = "center",
  columns = c(2:7)
 ) %>%
  tab_source_note(
    source_note = md("*k* = number of studies, *d* = Cohen's d effect-size, CI = confidence intervals")
  )

)
```

::: notes
-   This is a table showing the primary results of the Main meta-analysis.

-   Circle main parts of the table.

-   Take home point, is that. Routine treatment are effective across conditions.

-   Little difference between domains.
:::

------------------------------------------------------------------------

```{r}
#| include: true
#| eval: true
#| label: fig-effectiveness-comparisons
#| fig-cap: "Comparisons to Past Effectiveness Reviews."
library(tidyverse)
library(gt)

#gt::as_raw_html(
  
tribble(
  ~Paper,                      ~Condition,                 ~Treatment,  ~Method,                ~Studies,  ~es, ~ci.lower, ~ci.upper,
"Cahill et al., (2010)",      "Various",                   "Various",  "Review & Meta-Analysis",  31,        1.29,     1.26,         1.33,
#"Hunsley et al., (2014)",     "Mood & Anxiety Disorders",  "Various",  "Narrative Review",        NA,          NA,      NA,         NA,
"Van Ingen et al., (2009)",   "Anxiety Disorders",         "CBT",      "Review & Meta-Analysis",  11,        1.35,     NA,         NA,
"Stewart et al., (2009)",     "Panic",                     "CBT",      "Review & Meta-Analysis",  9 ,        1.01,     0.77,         1.25,
"Stewart et al., (2009)",     "SAD",                       "CBT",      "Review & Meta-Analysis",  11,        1.04,     0.79,         1.29,
"Stewart et al., (2009)",     "PTSD",                      "CBT",      "Review & Meta-Analysis",  6,         2.59,     2.06,         3.13,
"Stewart et al., (2009)",     "GAD",                       "CBT",      "Review & Meta-Analysis",  11,        0.89,     0.77,         1.07,
"Stewart et al., (2009)",     "OCD",                       "CBT",      "Review & Meta-Analysis",  11,        1.32,     1.19,         1.45,
#"Shaddish et al., (2000)",    "Various",                   "Various",  "Meta-Analysis",           90,         NA,      NA,         NA,
"Wakefield et al., (2020)",   "Depression",                "IAPT",     "Meta-Analysis",           46,        0.87,     0.78,         0.96,
"Wakefield et al., (2020)",   "Anxiety",                   "IAPT",     "Meta-Analysis",           41,        0.88,     0.79,         0.97,
"Wakefield et al., (2020)",   "Functioning",               "IAPT",     "Meta-Analysis",           19,        0.55,     0.48,         0.61,
"Gaskell et al., (2023)",      "Depression",                "IAPT",     "Meta-Analysis",          122,        0.96,     0.88,      1.04,
"Gaskell et al., (2023)",      "Anxiety",                   "IAPT",     "Meta-Analysis",          69,         0.8,      0.71,      0.90,
"Gaskell et al., (2023)",      "Other",                     "IAPT",     "Meta-Analysis",          158,        1.01,     0.93,      1.09


) %>%
  mutate(
    n.prop = (max(Studies)/100)*Studies
  ) %>% 
  ggplot(aes(x = Condition)) +
    scale_y_continuous(n.breaks = 10) +
  geom_point(aes(y = es, size = Studies), width = 0, shape = 18) +
  geom_errorbar(aes(ymin = ci.lower, ymax = ci.upper)) +
    facet_grid(
    rows = vars(Paper),
    scales = "free_y", 
    space = "free", labeller =
      labeller(Paper = label_wrap_gen(16))
  ) +
  #geom_hline(aes(yintercept = 0.96), linetype = "dashed", color = "red", linewidth = 1.4) +
  #geom_hline(aes(yintercept = 0), linetype = "dashed", color = "blue", linewidth = 1.4) +
  scale_y_continuous(n.breaks = 8, limits = c(0, 3.5)) +
  coord_flip() +
  theme_bw(base_size = 14) +
  labs(x = NULL,
      y = paste("Cohen's d"), #caption = "Note. red line = pooled effect-size; blue line = 0 (no effect)"
      ) +
  theme(strip.text.y.right = element_text(angle = 0, size = 12, colour = "black", face = "bold"),
        strip.background = element_rect(colour="black"),
        strip.placement = "left",
        legend.position = "none",
        plot.title.position = "plot",
        panel.grid.minor = element_blank()
   )

```

::: notes
-   This is a forest plot of different meta-analyses.

-   Each review is represented by a diamond, with the size of the box indicating the number of studies. The center of the diamond represents the effect-size (e.g., mean difference) of the effect size for that study, while the horizontal line extending from the box represents the confidence interval for the effect size. Further to the right are more effective.

-   In terms of comparing the to previous reviews. You can see the the current review, and the previous reviews, that provide meta-analytic findings are all included in this plot for comparison.

-   My interpretation: Actually quite a narrow range, with two outliers (wakefield and stewart)

-   Size of the diamond corresponds to the number of studies included in the meta.

-   Effect-sizes for each of the domains, are largely in fitting with previous reviews.
:::

## [Depression]{.red}

```{r}
#| include: true
#| eval: true
#| label: tbl-moderator-depression
#| tbl-cap: "Sub-group (categorical) moderator analyses for depression outcomes."

dat.depression <- 
   tribble(
        ~level,                  ~K,      ~SMD,      ~Q,           ~I2,      ~upper, ~lower,     ~mod,
        "mild",                   34,    1.03,     9550225.84,    "100%",     1.22, 0.85,        "severity",
        "university",             30,    0.98,     43207.72,      "100%",     1.16, 0.79,        "severity",
        "Secondary",              57,    0.98,     80913.95,      "100%",     1.11, 0.86,        "severity",
        "Residential",            15,    0.91,     237284.01,     "100%",     1.12, 0.7,        "severity",
        "include",                81,    0.93,     9730935.19,    "100%",     1.03, 0.84,        "analysis",
        "Completers",             59,    1.08,     221034.47,     "100%",     1.22, 0.94,        "analysis",
        "Outpatient",             121,    0.99,     9660158.7,    "100%",     1.08, 0.91,        "setting",
        "Residential",            16,    0.92,     240002.33,     "100%",     1.12, 0.72,        "setting",
        "N.America",              58,    1,     640493.04,        "100%",     1.11, 0.88,        "continent",
        "UK",                     44,    1.1,     3564904.55,     "100%",     1.26, 0.94,        "continent",
        "Europe",                 29,    0.95,     60424.34,      "100%",     1.12, 0.77,        "continent",
        "Australasia",            4,    0.67,     7087.67,        "100%",     1.01, 0.33,        "continent",
        "Asia",                   5,    0.59,     91.78,          "96%",      0.8, 0.37,        "continent",
        "psychodynamic",          24,    1.03,     41984.43,      "100%",     1.2, 0.86,        "therapy modality",
        "Counselling",            6,    0.89,     3471906.01,     "100%",     1.1, 0.69,        "therapy modality",
        "cognitive-behavioural",  90,    1,     393181.5,         "100%",     1.11, 0.89,        "therapy modality",
        "Other",                  20,    0.96,     307948.08,     "100%",     1.17, 0.75,        "therapy modality",
        "routine evaluations",    118,    1,     9955258.72,      "100%",     1.09, 0.91,        "Tretament stage",
        "preliminary studies",    22,    0.95,     546.66,        "96%",     1.12, 0.78,        "Tretament stage",
        "qualified",              121,    1.01,     9878905.77,   "100%",     1.1, 0.92,        "experience",
        "trainees",               19,    0.9,     76281.83,       "100%",     1.06, 0.74,        "experience",
        "BDI",                    34,    1.02,     121013.68,     "100%",     1.18, 0.86,        "measure",
        "PHQ-9",                  30,    1.01,     3495045.61,    "100%",     1.22, 0.81,        "measure",
        "large",                  74,    1.02,     9949550,       "100%",     1.13, 0.91,        "sample size",
        "small",                  33,    0.85,     625.88,        "95%",     0.99, 0.7,          "sample size",
        "",                       124,    -.001,     NA,           NA,     NA,  NA,            "publication year",
        "",                       124,    -.004,     NA,           NA,     NA,  NA,            "sample age",
        "",                       124,    0.13,      NA,           NA,     NA,  NA,              "% female",
        ) %>% 
  mutate(
    mod = str_to_title(mod),
    level = str_to_title(level),
    level = recode(level, "Uk" = "UK", "N.america" = "North America", "Europe" = "Mainland Europe",
                   "Bdi" = "BDI", "Phq-9" = "PHQ 9"),
    )

gt::as_raw_html(
  
dat.depression %>% 
  mutate("ci" = ifelse (is.na(lower), NA, paste(lower, upper, sep = "-")
  ), es = SMD) %>%
  group_by(mod) %>% 
  gt(rowname_col = "level") %>%
    cols_hide(columns = c(Q, upper, lower))  %>%
  tab_options(
    #row_group.background.color = "grey",
    row_group.font.size = 16,
    row_group.font.weight = "bold",
    column_labels.font.weight = "bold",
    table.font.size = 14,
    data_row.padding = px(6),
    table.width = pct(85),
    row_group.padding = px(4)
  ) %>%
    cols_label(
    K = md("*k*"),
    SMD = md("*d*"),
    ci = "95% CI",
    I2 = md("*I*<sup>2</sup>"),
    es = "Forest Plot",
    ) %>% 
    tab_header(
    title = md("**Depression** Outcomes"),
  ) %>%
    cols_align(
    align = "center",
    columns = c(2:10)
    ) %>%
  sub_missing(columns = 1:9, missing_text = "") %>%
  gt::opt_row_striping(row_striping = T) %>%
  opt_stylize(style = 6, color = "red") %>%
gtExtras::gt_plt_conf_int(es, ci_columns = c(lower, upper), text_size = 2, ref_line = 0.96, width = 100,
  palette = c("grey", "lightgrey", "black", "red"),
text_args = list(accuracy = .01)
  ) %>%
cols_align(
  align = "center",
  columns = c(2:10)
 )  %>%
  tab_source_note(
    source_note = md("*k* = number of studies, *d* = Cohen's d effect-size, CI = confidence intervals<br>**Summary**: *d* = 0.96, *k* = 124, Tau<sup>2</sup> = 0.17[SE = 0.02], I<sup>2</sup> = 99.99%, R<sup>2</sup> = 19.28%")
    ) %>% 
   fmt_markdown(columns = everything())

) 

```

::: notes
-   Not going to go through each moderator for each domain. Set of moderators for each domain, therefore there is one of these tables for each domain.

-   There is a slide coming up shortly that should bring attention to the more salient findings.

-   This is a table illustrating the different moderators, and the different levels within the moderators.

-   Provide caveat about moderators. General heuristic to assess what conditions tend to fare slightly better, but this is based on an analysis which is likely to be underpowered and based upon observational findings.
:::

------------------------------------------------------------------------

##  {background-color="white" style="color: #FF644E"}

```{r}
#| include: true
#| eval: true
#| label: fig-moderator-depression
#| fig-cap: "Sub-group (categorical) moderator analyses for depression outcomes."
#| fig-width: 25
#| fig-height: 18

dat.depression %>%
  arrange(mod, level) %>% 
  mutate(level = recode(level, "Include" = "All starting treatment")) %>%
  filter(level != "" ) %>%
  ggplot(aes(x = level, y = SMD)) +
  geom_point() +
  geom_errorbar(aes(ymin = lower, ymax = upper)) +
  geom_hline(aes(yintercept = 0.96), linetype = "dashed", color = "red", linewidth = 1.4) +
  geom_hline(aes(yintercept = 0), linetype = "dashed", color = "blue", linewidth = 1.4) +
  scale_y_continuous(n.breaks = 10) +
  facet_grid(
    rows = vars(mod),
    scales = "free", space = "free", labeller =
      labeller(mod = label_wrap_gen(8))
  ) + 
  coord_flip() +
  theme_bw() +
  labs(x = "Sub-group moderator level", y = paste("Cohen's d"), caption = "Note. red line = pooled effect-size; blue line = 0 (no effect)") +
  theme(strip.text.y.right = element_text(angle = 270, size = 21, colour = "white", face = "bold"),
        strip.background = element_rect(colour="black",
                                        fill="#E4220C"),
        strip.placement = "left",
        legend.position = "bottom",
        plot.title.position = "plot",
        text = element_text(size = 22),
        #strip.text = element_text(face = "bold", size = 12),
        axis.text.x = element_text(size = 22),
        panel.grid.minor = element_blank()
   )

```

------------------------------------------------------------------------

## [Anxiety]{.blue}

```{r}
#| include: true
#| eval: true
#| label: tbl-moderator-anxiety
#| tbl-cap: "Sub-group (categorical) moderator analyses for anxiety outcomes."
 dat.anxiety <- 
   tribble(
        ~level,                   ~K,  ~SMD,   ~Q,           ~I2,    ~upper, ~lower,    ~mod,
        "mild",                  22,   0.99,  334405.48,   "100%",  1.2,     0.79,   "severity",
        "Secondary",             24,   0.63,  30702.22,    "100%",  0.76,    0.5,    "severity",
        "Residential",            8,    0.59,  108223.63,   "100%",  0.9,     0.29,   "severity",
        "university",            29,   1.01,  32067.93,    "100%",  1.2,     0.83,   "severity",
        "include",               58,   0.81,  517063.05,   "100%",  0.93,    0.69,   "analysis",
        "Completers",            26,   0.96,  92492.19,    "100%",  1.14,    0.77,   "analysis",
        "Outpatient",            75,   0.89,  440122.14,   "100%",  0.99,    0.78,   "setting",
        "Residential",           9,    0.58,  157933.03,   "100%",  0.85,    0.31,   "setting",
        "N.America",             32,   0.91,  230641.72,   "100%",  1.1,     0.72,   "continent",
        "UK",                    25,   0.89,  115765.33,   "100%",  1.09,    0.7,    "continent",
        "Europe",                20,   0.79,  27960.45,    "100%",  0.93,    0.65,   "continent",
        "Australasia",           4,    0.61,  3781.78,     "100%",  1.01,    0.21,   "continent",
        "Asia",                  3,    0.59,  3.33,        "40%",   0.68,    0.49,   "continent",
        "psychodynamic",        12,    0.9,   11879.61,    "100%",   1.04,   0.75,   "therapy modality",
        "Counselling",          2,     0.43,  28.37,        "96%",   0.49,   0.38,   "therapy modality",
        "cognitive-behavioural",62,    0.87,  174811.7,    "100%",      1,   0.74,   "therapy modality",
        "Other",                8,     0.75,  155956.84,    "100%",  0.97,   0.53,   "therapy modality",
        "routine evaluations",  74,    0.85,  635244.53,    "100%",  0.96,   0.74,   "Tretament stage",
        "preliminary studies",  10,    0.87,  639.27,       "99%",   1.14,   0.61,   "Tretament stage",
        "qualified",            66,    0.78,  502201.12,    "100%",  0.88,   0.68,   "experience",
        "trainees",             18,    1.12,  59913.29,     "100%",  1.39,   0.86,   "experience",
        "BAI",                  19,    0.71,  36173.3,      "100%",  0.88,   0.54,   "measure",
        "GAD-7",                19,    0.96,  241386.08,    "100%",  1.15,   0.78,   "measure",
        "large",                45,    0.84,  635426.98,    "100%",  0.95,   0.72,   "sample size",
        "medium",               13,    0.93,  2069.64,      "99%",    1.3,   0.57,   "sample size",
        "small",                26,    0.84,  898.19,       "97%",   1.03,   0.66,   "sample size",
        "",                     78,    0.01,       NA,       NA,     NA,  NA,            "publication year",
        "",                     78,    -0.01,      NA,       NA,     NA,  NA,            "sample age",
        "",                     78,    -0.22,      NA,       NA,     NA,  NA,              "% female"
        ) %>% 
  mutate(
    mod = str_to_title(mod),
    level = str_to_title(level),
    level = recode(level, "Uk" = "UK", "N.america" = "North America", "Europe" = "Mainland Europe",
                   "Bai" = "BAI", "Gad-7" = "GAD 7"),
    ) 
   
gt::as_raw_html(
  
dat.anxiety %>% 
  mutate("ci" = ifelse (is.na(lower), NA, paste(lower, upper, sep = "-")
  ), es = SMD) %>%
  group_by(mod) %>% 
  gt(rowname_col = "level") %>%
    cols_hide(columns = c(Q, upper, lower))  %>%
  tab_options(
    #row_group.background.color = "grey",
    row_group.font.size = 16,
    row_group.font.weight = "bold",
    column_labels.font.weight = "bold",
    table.font.size = 14,
    data_row.padding = px(6),
    table.width = pct(85),
    row_group.padding = px(4)
  ) %>%
    cols_label(    K = md("*k*"),
    SMD = md("Cohen's *d*"),
    ci = "95% CI",
    I2 = md("*I*<sup>2</sup>"),
    es = "Forest Plot"
    ) %>% 
    tab_header(
    title = md("**Anxiety** Outcomes"),
  ) %>%
    cols_align(
    align = "center",
    columns = c(2:10)
    ) %>%
  sub_missing(columns = 1:7, missing_text = "-") %>%
  gt::opt_row_striping(row_striping = T) %>%
  opt_stylize(style = 6, color = "blue") %>%
gtExtras::gt_plt_conf_int(es, ci_columns = c(lower, upper), text_size = 2, ref_line = 0.8, width = 100,
  palette = c("grey", "lightgrey", "black", "blue"),
text_args = list(accuracy = .01)
  ) %>%
cols_align(
  align = "center",
  columns = c(2:10)
 )  %>%
  tab_source_note(
    source_note = md("*k* = number of studies, *d* = Cohen's d effect-size, CI = confidence intervals<br>**Summary**: *d* = 0.8, *k* = 78, Tau<sup>2</sup> = 0.13[SE = 0.02], I<sup>2</sup> = 99.95%, R<sup>2</sup> = 40.55%")
    )

)   

```

------------------------------------------------------------------------

##  {background-color="white" style="color: #00A1FF"}

```{r}
#| include: true
#| eval: true
#| label: fig-moderator-anxiety
#| fig-cap: "Sub-group (categorical) moderator analyses for anxiety outcomes."
#| fig-width: 20
#| fig-height: 16

dat.anxiety %>%
  arrange(mod, level) %>% 
  mutate(level = recode(level, "Include" = "All starting treatment")) %>%
  filter(level != "" ) %>%
  ggplot(aes(x = level, y = SMD)) +
  geom_point() +
  geom_errorbar(aes(ymin = lower, ymax = upper)) +
  geom_hline(aes(yintercept = 0.80), linetype = "dashed", color = "red") +
  geom_hline(aes(yintercept = 0), linetype = "dashed", color = "blue") +
  scale_y_continuous(n.breaks = 10) +
  facet_grid(
    rows = vars(mod),
    scales = "free", space = "free", labeller =
      labeller(mod = label_wrap_gen(8))
  ) + 
  coord_flip() +
  theme_bw() +
  labs(x = "Sub-group moderator level", y = paste("Cohen's d"), caption = "Note. red line = pooled effect-size; blue line = 0 (no effect)") +
  theme(strip.text.y.right = element_text(colour = "white", angle = 270, size = 17),
        strip.placement = "left",
        strip.background = element_rect(colour="black",
                                        fill="#00A1FF"),
        legend.position = "bottom",
        plot.title.position = "plot",
        text = element_text(size = 20),
        #strip.text = element_text(face = "bold", size = 12),
        axis.text.x = element_text(size = 20),
        panel.grid.minor = element_blank()
   )

```

------------------------------------------------------------------------

## [Other]{.green}

```{r}
#| include: true
#| eval: true
#| label: tbl-moderator-other
#| tbl-cap: "Sub-group (categorical) moderator analyses for other outcomes."

dat.other <- 
tribble(
 ~level,                   ~K,   ~SMD,      ~Q,       ~I2,      ~upper, ~lower, ~mod,
 "mild",                   61,   1.08,   39097618.6,  "100%",    1.21, 0.95,      "severity",
 "Secondary",              62,   0.98,   111313.98,   "100%",    1.12, 0.84,      "severity",
 "Residential",            27,   1.09,   66242.24,    "100%",    1.26, 0.91,      "severity",
 "university",             28,   0.82,   44711.91,    "100%",    0.95, 0.7,      "severity",
 "include",                95,   0.98,   12421993.52, "100%",    1.09, 0.87,      "analysis",
 "Completers",             89,   1.08,   10540486.3,  "100%",    1.18, 0.97,      "analysis",
 "Outpatient",             153,  1,   104250384.75,   "100%",    1.08, 0.92,      "setting",
 "Residential",            28,   1.08,   67693.6,     "100%",    1.25, 0.91,      "setting",
 "UK",                     68,   1.02,   92810921.73, "100%",    1.13, 0.92,      "continent",
 "N.America",              60,   1.07,   4606355.34,  "100%",    1.25, 0.9,      "continent",
 "Europe",                 47,   1,   157855.31,      "100%",    1.12, 0.88,      "continent",
 "Australasia",            4,    0.81,   330.52,      "99%",     0.9, 0.72,      "continent",
 "Asia",                   5,    0.9,   575.15,       "99%",     1.2, 0.61,      "continent",
 "cognitive-behavioural",  83,   1.18,   178432.53,   "100%",    1.32, 1.05,      "therapy modality",
 "psychodynamic",          36,   0.93,   49292.89,    "100%",    1.07, 0.79,      "therapy modality",
 "Counselling",            19,   0.9,   318722.49,    "100%",    1.06, 0.75,      "therapy modality",
 "Other",                  46,   0.87,   103700450.06,"100%",    0.98, 0.76,      "therapy modality",
 "preliminary studies",    24,   1.06,   4742.5,      "100%",    1.29, 0.82,      "Tretament stage",
 "routine evaluations",    160,  1.02,   104380709.35,"100%",    1.1, 0.94,      "Tretament stage",
 "qualified",              158,  1.07,   104283036.81,"100%",    1.16, 0.99,      "experience",
 "trainees",               26,   0.77,   71069.62,    "100%",    0.89, 0.65,      "experience",
 "BSI-GSI",                26,   0.87,   9966.85,     "100%",    1, 0.73,      "measure",
 "CORE-OM",                35,   1.04,   72198841.45, "100%",    1.18, 0.9,      "measure",
 "OQ-45",                  13,   0.57,   1090596.15,  "100%",    0.74, 0.41,      "measure",
 "SCL (Global)",           22,   1.05,   15779.11,    "100%",    1.23, 0.87,      "measure",
 "PCL",                    12,   1.29,   3642.32,     "100%",    1.61, 0.97,      "measure",
 "large",                  110,  1.01,   104379542.58,"100%",    1.1, 0.92,      "sample size",
 "medium",                 38,   1.11,   4366.03,     "99%",     1.3, 0.92,      "sample size",
 "small",                  36,   0.99,   1001.45,     "97%",     1.18, 0.81,      "sample size",
   "",                     153,  0.00,       NA,       NA,     NA,  NA,            "publication year",
   "",                     153,  -0.00,      NA,       NA,     NA,  NA,            "sample age",
   "",                     153,  -0.14,      NA,       NA,     NA,  NA,              "% female"
 )   %>% 
  mutate(
    mod = str_to_title(mod),
    level = str_to_title(level),
    level = recode(level, "Uk" = "UK", "N.america" = "North America", "Europe" = "Mainland Europe",
                   "Bsi-Gsi" = "BSI-GSI", "Scl (Global)" = "SCL (Global)",
                   "Core-Om" = "CORE-OM", "Pcl" = "PCL",
                   "Oq-45" = "OQ-45"),
    ) 

gt::as_raw_html(
  
dat.other %>% 
  mutate("ci" = ifelse (is.na(lower), NA, paste(lower, upper, sep = "-")
  ), es = SMD) %>%
  group_by(mod) %>% 
  gt(rowname_col = "level") %>%
    cols_hide(columns = c(Q, upper, lower))  %>%
  tab_options(
    #row_group.background.color = "grey",
    row_group.font.size = 16,
    row_group.font.weight = "bold",
    column_labels.font.weight = "bold",
    table.font.size = 14,
    data_row.padding = px(6),
    table.width = pct(85),
    row_group.padding = px(4)
  ) %>%
    cols_label(
    K = md("*k*"),
    SMD = md("Cohen's *d*"),
    ci = "95% CI",
    I2 = md("*I*<sup>2</sup>"),
    es = "Forest Plot"
    ) %>% 
    tab_header(
    title = md("**Other** Outcomes"),
  ) %>%
    cols_align(
    align = "center",
    columns = c(2:10)
    ) %>%
  sub_missing(columns = 1:7, missing_text = "-") %>%
  gt::opt_row_striping(row_striping = T) %>%
  opt_stylize(style = 6, color = "green") %>%
gtExtras::gt_plt_conf_int(es, ci_columns = c(lower, upper), text_size = 2, ref_line = 1.01, width = 100,
  palette = c("grey", "lightgrey", "black", "green"),
text_args = list(accuracy = .01)
  ) %>%
cols_align(
  align = "center",
  columns = c(2:10)
 )   %>%
  tab_source_note(
    source_note = md("*k* = number of studies, *d* = Cohen's d effect-size, CI = confidence intervals<br>**Summary**: *d* = 1.01, *k* = 153, Tau<sup>2</sup> = 0.24[SE = 0.03], I<sup>2</sup> = 100%, R<sup>2</sup> = 21.44%")
    )

)
```

------------------------------------------------------------------------

##  {background-color="white" style="color: #038901"}

```{r}
#| include: true
#| eval: true
#| label: fig-moderator-other
#| fig-cap: "Sub-group (categorical) moderator analyses for other outcomes."
#| fig-width: 20
#| fig-height: 16

dat.other %>%
  arrange(mod, level) %>% 
  mutate(level = recode(level, "Include" = "All starting treatment")) %>%
  filter(level != "" ) %>%
  ggplot(aes(x = level, y = SMD)) +
  geom_point() +
  geom_errorbar(aes(ymin = lower, ymax = upper)) +
  geom_hline(aes(yintercept = 1.01), linetype = "dashed", color = "red") +
  geom_hline(aes(yintercept = 0), linetype = "dashed", color = "blue") +
  scale_y_continuous(n.breaks = 10) +
  facet_grid(
    rows = vars(mod),
    scales = "free", space = "free", labeller =
      labeller(mod = label_wrap_gen(8))
  ) + 
  coord_flip() +
  theme_bw() +
  labs(x = "Sub-group moderator level", y = paste("Cohen's d"), caption = "Note. red line = pooled effect-size; blue line = 0 (no effect)") +
  theme(strip.text.y.right = element_text(angle = 270, size = 17, colour = "white"),
        strip.placement = "left",
        strip.background = element_rect(colour="black",
                                        fill="#038901"),
        legend.position = "bottom",
        plot.title.position = "plot",
        text = element_text(size = 20),
        #strip.text = element_text(face = "bold", size = 12),
        axis.text.x = element_text(size = 20),
        panel.grid.minor = element_blank()
   )

```

## [Multiple Meta Regression]{.pink}

```{r}
#| include: true
#| eval: true
#| label: tbl-multiple-meta
#| tbl-cap: "Multiple meta-regression of moderators included in the review."

gt::as_raw_html(
  
  tribble(
~Moderator,        ~Depression,  ~Anxiety,  ~Other,        ~Notes,
  "Continent",        paste(emo::ji("check")),      paste(emo::ji("check")),	      paste(emo::ji("cross mark")),            "**Depression**: UK samples had larger effect sizes compared to samples from Asia.<br>
                                                                **Anxiety**: UK samples had larger effect sizes compared to samples from mainland Europe.",
  "Severity",           paste(emo::ji("cross mark")),       paste(emo::ji("check")),        paste(emo::ji("cross mark")),            "**Anxiety**: Mild samples had larger effect sizes than moderate or severe samples.",
  "Modality",           paste(emo::ji("cross mark")),       paste(emo::ji("check")),       paste(emo::ji("check")),          "**Anxiety**: CBT outperformed counselling interventions.<br>
                                                                **Other**: CBT outperformed unspecified and psychodynamic interventions.",
  "Treatment Stage",    paste(emo::ji("cross mark")),        paste(emo::ji("cross mark")),	       paste(emo::ji("cross mark")),            NA,
  "Analysis",          paste(emo::ji("check")),              paste(emo::ji("cross mark")),         paste(emo::ji("cross mark")),            "**Depression**: completer samples outperformed ITT.",
  "Experience",        paste(emo::ji("check")),              paste(emo::ji("cross mark")),	       paste(emo::ji("cross mark")),            "**Depression**: qualified staff outperformed trainees.",        
  "Sample Size",        paste(emo::ji("cross mark")),        paste(emo::ji("cross mark")),         paste(emo::ji("cross mark")),            NA,        
  "Publication Year",   paste(emo::ji("cross mark")),        paste(emo::ji("cross mark")),         paste(emo::ji("cross mark")),            NA,
  "Sample Age",         paste(emo::ji("cross mark")),        paste(emo::ji("cross mark")),         paste(emo::ji("cross mark")),            NA,
 " % Female",           paste(emo::ji("cross mark")),        paste(emo::ji("cross mark")),         paste(emo::ji("cross mark")),            NA
) %>% 
  gt(rowname_col = "Moderator") %>%
  tab_options(
    #row_group.background.color = "grey",
    row_group.font.size = 16,
    row_group.font.weight = "bold",
    column_labels.font.weight = "bold",
    table.font.size = 14,
    data_row.padding = px(6),
    table.width = pct(85),
    row_group.padding = px(4)
  ) %>% 
    tab_header(
    title = md("**Multi-Meta Regression**"),
  ) %>%
    cols_align(
    align = "center",
    columns = c(2:4)
    )  %>% 
   fmt_markdown(columns = everything()) %>%
  sub_missing(columns = 1:5, missing_text = "") %>%
  gt::opt_row_striping(row_striping = T) %>%
  opt_stylize(style = 6, color = "pink")


  ) 

```

::: notes
-   As we are using a lot of moderator variables. One thing we need to be aware of, is that two variables may be accounting for a shared proportion of heterogeneity. And therefore, like when you would run regression. It is best to do a multiple regression with all your variables, as opposed to running a linear regression for every variable.

-   For the moderator of different continents:

    -   **Continent:** It seemed that when entered in the multiple regression. The UK produced greater effect-size than Asia for depression outcomes; AND the UK produced greater effect-sizes than mainland Europe for anxiety.

    -   **Severity:** for anxiety based outcomes, those treated in services for milder conditions demonstrated greater amounts of change than services treatment more severe/complex conditions.

    -   **Modality:** For anxiety, CBT outperformed counselling. While for Other treatments, CBT outperformed psychodynamic treatments.
:::

## [Benchmarks]{.pink}

```{r}
#| include: true
#| eval: true
#| label: tbl-moderator-benchmarks
#| tbl-cap: "Benchmarks for routine services based on individual study sample quartiles."

# dat.benchmarks <-
#   tribble(
# ~Group,       ~Domain,     ~Outpatient,	           ~Inpatient,	           ~UCC,                 ~"Uni Clinics",
# "Top 25%",    "Depression",	 "d = 1.68 [1.53-1.83]", "d = 1.34 [1.16-1.52]",  NA,                   "d = 1.77 [1.50-2.03]",
# "Top 25%",    "Anxiety",     "d = 1.56 [1.38-1.73", "d = 1.07 [1.04-1.09]",   NA,                   "d = 1.80 [1.57-2.02]",
# "Top 25%",    "Other",       "d = 1.70 [1.54-1.86]", "d = 1.67 [1.37-1.97]", "d - 1.47 [1.24-1.69]","d = 1.14 [1.10-1.18]",
# "Average",    "Depression",	 "d = 0.94 [0.90-0.97]", "d = 0.98 [0.81-1.15]",  NA,                   "d = 0.91 [0.87-0.95]",
# "Average",    "Anxiety",     "d = 0.84 [0.78-0.89]", "d = 0.67 [0.42-0.92]",  NA,                   "d = 1.80 [1.57-2.02]",
# "Average",    "Other",       "d = 0.92 [0.89-0.96]", "d = 1.04 [0.96-1.11]", "d = 0.94 [0.84-1.03]","d = 0.86 [0.77-0.94]",
# "Bottom 25%", "Depression",	 "d = 0.46 [0.41-0.52]", "d = 0.38 [0.26-0.5]",   NA,                    "d = 0.40 [0.27-0.54]",
# "Bottom 25%", "Anxiety",     "d = 0.37 [0.33-0.42]", "d = 0.13 [0.03-0.29]",  NA,                   "d = 0.51 [0.44-0.57]",
# "Bottom 25%", "Other",       "d = 0.49 [0.43-0.54]", "d = 0.58 [0.46-0.69]", "d = 0.64 [0.61-0.67]","d = 0.41 [0.23-0.59]",
# )



dat.benchmarks <-
  tribble(
~Group,       ~Domain,       ~Setting,           ~es,     ~lower, ~upper,
"Top 25%",    "Depression",	 "Outpatient Services",       1.68,   1.53,     1.83,    
"Top 25%",    "Anxiety",     "Outpatient Services",       1.56,   1.38,     1.73,    
"Top 25%",    "Other",       "Outpatient Services",       1.70,   1.54,     1.86,    
"Average",    "Depression",	 "Outpatient Services",       0.94,   0.90,     0.97,    
"Average",    "Anxiety",     "Outpatient Services",       0.84,   0.78,     0.89,    
"Average",    "Other",       "Outpatient Services",       0.92,   0.89,     0.96,    
"Bottom 25%", "Depression",	 "Outpatient Services",       0.46,   0.41,     0.52,    
"Bottom 25%", "Anxiety",     "Outpatient Services",       0.37,   0.33,     0.42,    
"Bottom 25%", "Other",       "Outpatient Services",       0.49,   0.43,     0.54,    
"Top 25%",    "Depression",	 "Inpatient Services",        1.34,   1.16,     1.52,    
"Top 25%",    "Anxiety",     "Inpatient Services",        1.07,   1.04,     1.09,    
"Top 25%",    "Other",       "Inpatient Services",        1.67,   1.37,     1.97,    
"Average",    "Depression",	 "Inpatient Services",        0.98,   0.81,     1.15,    
"Average",    "Anxiety",     "Inpatient Services",        0.67,   0.42,     0.92,    
"Average",    "Other",       "Inpatient Services",        1.04,   0.96,     1.11,    
"Bottom 25%", "Depression",	 "Inpatient Services",        0.38,   0.26,     0.5,      
"Bottom 25%", "Anxiety",     "Inpatient Services",        0.13,   0.03,     0.29,    
"Bottom 25%", "Other",       "Inpatient Services",        0.58,   0.46,     0.69,    
"Top 25%",    "Depression",	 "University Counselling Centers",                NA,   NA,        NA,                     
"Top 25%",    "Anxiety",     "University Counselling Centers",                NA,   NA,        NA,                    
"Top 25%",    "Other",       "University Counselling Centers",             1.47 ,   1.24,     1.69,  
"Average",    "Depression",	 "University Counselling Centers",                NA,  NA,         NA,         
"Average",    "Anxiety",     "University Counselling Centers",                NA,  NA,         NA,         
"Average",    "Other",       "University Counselling Centers",             0.94,    0.84,       1.03,  
"Bottom 25%", "Depression",	 "University Counselling Centers",                NA,   NA,        NA,                  
"Bottom 25%", "Anxiety",     "University Counselling Centers",                NA,   NA,        NA,                  
"Bottom 25%", "Other",       "University Counselling Centers",              0.64,  0.61,      0.67,  
"Top 25%",    "Depression",	 "University Outpatient Clinics",      1.77,  1.50,      2.03,
"Top 25%",    "Anxiety",     "University Outpatient Clinics",      1.80,  1.57,      2.02,
"Top 25%",    "Other",       "University Outpatient Clinics",      1.14,  1.10,      1.18,
"Average",    "Depression",	 "University Outpatient Clinics",      0.91,  0.87,      0.95,
"Average",    "Anxiety",     "University Outpatient Clinics",      1.80,  1.57,      2.02,
"Average",    "Other",       "University Outpatient Clinics",      0.86,  0.77,      0.94,
"Bottom 25%", "Depression",	 "University Outpatient Clinics",      0.40,  0.27,      0.54,
"Bottom 25%", "Anxiety",     "University Outpatient Clinics",      0.51,  0.44,      0.57,
"Bottom 25%", "Other",       "University Outpatient Clinics",      0.41,  0.23,      0.59
) %>% mutate(d = es,
             ci = paste(lower, upper, sep = "-")
) %>% relocate(Group, Domain, Setting, es, ci,  lower, upper) 





gt::as_raw_html(
  
dat.benchmarks %>% 
  drop_na(es) %>% 
  group_by(Domain, Setting) %>%
  arrange(Domain) %>% 
  gt(rowname_col = "Group") %>%
    cols_hide(columns = c(upper, lower))  %>%
  tab_options(
    row_group.font.size = 16,
    row_group.font.weight = "bold",
    column_labels.font.weight = "bold",
    table.font.size = 14,
    data_row.padding = px(6),
    table.width = pct(85),
    row_group.padding = px(4),
  ) %>%
    fmt_markdown(columns = everything()) %>%
    cols_label(
    ci = "95% CI",
    es = md("Cohen's *d*"),
    d = "Forest Plot"
      ) %>% 
    tab_header(
    title = md("**Benchmarks**"),
  ) %>%
    cols_align(
    align = "center",
    columns = c(2:8)
    ) %>% 
  sub_missing(columns = 1:8, missing_text = "-") %>%
  gt::opt_row_striping(row_striping = T) %>%
  opt_stylize(style = 6, color = "pink") %>%
  gtExtras::gt_plt_conf_int(d, ci_columns = c(lower, upper), text_size = 2, ref_line = 1, width = 100,
  palette = c("grey", "lightgrey", "black", "pink"),
text_args = list(accuracy = .01)
  )
)
```

::: notes
-   For me this is perhaps one of the more interesting parts of the review.

-   Doing a review on so many studies means that we have, what is, in effect, normative data for routine services.

-   Now it is debatable how much published PBE represents unpublished PBE but still it is the closest thing we have to be able to develop some clinical benchmarks for what is a high performing service, an average services, or a low performing service.

-   So you can see for the top tier (anxiety outpatients) that it is broken down into quartiles.

-   So, it is hopes that services will be able to use this table to help them work our, roughly, how they are performing as a clinical service.
:::

::: {style="text-align: center; padding: 200px 0;"}
# What it means {background-color="#01364C"}
:::

## What it Means?

-   Broadest meta-analytic study of routine therapy outcomes (*N* = 233,140, *k* = 223)
-   Comparable (large) rates of effectiveness to other reviews of practice based evidence.
-   All continents demonstrated positive change (*d* = 0.59--1.10) supporting the **universality hypothesis** (i.e., that psychotherapy is assumed to work across cultures; Flückiger et al., 2018).
-   Some interesting findings from moderators (however there are power issues).

::: notes
-   Read from slides.
:::

## Making Sense of the Moderators

-   **Continental Differences? UK/US appeared to outperform some regions.**
    -   Potentially influenced by differences in models of training, service structures, therapy provision and emphasis on evidence-based practice?
    -   *Note.* Some continents had very few studies.
-   **So is Severity not Associated with Effect-Size?**
    -   Inpatient **anxiety** samples fared less well.
    -   Baseline severity not important for depression?
    -   *Note.* Was our variable an Imprecise proxy?
-   **Long live the Dodo Bird?**
    -   CBT outperformed other treatments for the **other** outcomes category. Potentially due to influence on specific conditions (e.g., PTSD, OCD)?
    -   Absence of evidence for CBT being superior for **anxiety** or **depression** category outcomes.
-   **Maybe there [is]{.underline} something to say for Clinician Experience?**
    -   Qualified clinicians out performed trainees for **depression** and **other** category outcomes.
    -   Trainees fared slightly better for anxiety.
        -   Potentially less likely to drift from EBP?

::: {style="text-align: center; padding: 200px 0;"}
# Limitations {background-color="#01364C"}
:::

## Limitations and Opportunities

::: columns
::: {.column width="50%"}
-   :x: Reliance on Observational Evidence.
-   :x: Outcome Domains & Statistical Dependency
-   :x: Did Treatments Intended = Treatment Received.
-   :x: Only Reflects Changes During Treatment Phase.
-   :x: Exclusively Self-Report Data.
:::

::: {.column width="50%"}
-   :white_check_mark: Nevertheless, valuable benchmarks.
-   :white_check_mark: Robust variance and/or IPDMA.
-   :white_check_mark: Re-analysis Focusing upon Fidelity Checks.
-   :white_check_mark: Re-analysis Focusing upon Follow Up Evidence.
-   :white_check_mark: Reliance upon Clinician Report as Moderator.
:::
:::

::: notes
Read from slides.

-   Regression to the mean less likely.
:::

::: {style="text-align: center; padding: 200px 0;"}
# Conclusions {background-color="#01364C"}
:::

## Conclusion

-   Treatments are highly effective in routine practice.

-   **Nevertheless**, effects vary considerably across services.

-   Performance benchmarks may help routine services through evaluation and practice development initiatives.

-   **Next step:** Do treatment effects last?

::: {style="text-align: center; padding: 200px 0;"}
# Developments {background-color="#01364C"}
:::

## Publication {background-color="white"}

![Gaskell, C., Simmonds-Buckley, M., Kellett, S., Stockton, C., Somerville, E,. Rogerson E., & Delgadillo, J. (2023). The effectiveness of psychological interventions delivered in routine practice: Systematic review and meta-analysis. Administration and Policy in Mental Health and Mental Health Services Research. 50, 43--57. https://doi.org/10.1007/s10488-022-01225-y](files/img/publication.jpg){alt="Shiny App for plotting benchmarks" fig-align="center" width="700" height="900"}

::: notes
-   Now published, in administrations & policy in MH service research.
:::

## Web App {background-color="white"}

Allows services to generate an effect-size and compare it to benchmarks from the paper.

![Shiny App for plotting benchmarks.](files/img/app.jpg){fig-align="center"}

<https://chris-gaskell.shinyapps.io/effectiveness-meta-shiny>

::: notes
-   App is based on the outcomes from the individual studies in the meta-analyses.

-   It takes the previous benchmark tables presented earlier to a more granular level.

-   Allows service to input some basic service data and generate.
:::

## Lessons Learnt & Top Tips {visibility="hidden"}

1.  Watertight protocol.

2.  Project Management.

3.  Reproducible workflows.

::: {style="text-align: center; padding: 200px 0;"}
# Thanks for Listening! {background-color="#01364C"}
:::
